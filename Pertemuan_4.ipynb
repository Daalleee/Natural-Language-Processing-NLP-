{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrrPp5sDIvFUYNoK1rxl77",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daalleee/Natural-Language-Processing-NLP-/blob/main/Pertemuan_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalasi pustaka (jalankan sekali saja di terminal atau notebook)\n",
        "!pip install spacy pandas stanza transformers\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "# Data kalimat contoh Bahasa Indonesia dan Inggris\n",
        "texts = {\n",
        "    \"id\": [\n",
        "        \"Jokowi mengunjungi Universitas Indonesia di Depok.\",\n",
        "        \"Budi sedang belajar NLP bersama Ani di rumah.\",\n",
        "        \"Apple diluncurkan oleh Steve Jobs di Amerika Serikat.\"\n",
        "    ],\n",
        "    \"en\": [\n",
        "        \"President Jokowi visited the University of Indonesia in Depok.\",\n",
        "        \"Budi is studying NLP with Ani at home.\",\n",
        "        \"Apple was launched by Steve Jobs in the United States.\"\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICjGQvBjD5uv",
        "outputId": "64590732-c21e-4e04-d457-66d9fae31c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: stanza in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.17.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (from stanza) (2.15.0)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.12/dist-packages (from stanza) (5.29.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from stanza) (3.5)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from stanza) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (1.13.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->stanza) (3.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "import spacy\n",
        "\n",
        "# Inisialisasi pipeline Stanza untuk Bahasa Indonesia (tokenisasi dan POS)\n",
        "stanza.download(\"id\", processors=\"tokenize,pos\", verbose=False)\n",
        "nlp_id = stanza.Pipeline(\"id\", processors=\"tokenize,pos\", use_gpu=False)\n",
        "\n",
        "# Inisialisasi model NER Bahasa Indonesia dari Hugging Face\n",
        "NER_MODEL_ID = \"cahya/bert-base-indonesian-NER\"\n",
        "_tok = AutoTokenizer.from_pretrained(NER_MODEL_ID)\n",
        "_mdl = AutoModelForTokenClassification.from_pretrained(NER_MODEL_ID)\n",
        "ner_hf = pipeline(\n",
        "    \"token-classification\",\n",
        "    model=_mdl,\n",
        "    tokenizer=_tok,\n",
        "    aggregation_strategy=\"simple\"\n",
        ")\n",
        "\n",
        "# Inisialisasi spaCy untuk Bahasa Inggris\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Fungsi ekstraksi POS & NER Bahasa Indonesia\n",
        "def pos_ner_indonesian(text: str):\n",
        "    doc = nlp_id(text)\n",
        "    pos_tags = []\n",
        "    for sent in doc.sentences:\n",
        "        for w in sent.words:\n",
        "            pos_tags.append((w.text, w.upos))\n",
        "    ner_raw = ner_hf(text)\n",
        "    ner_entities = [(ent[\"word\"], ent[\"entity_group\"]) for ent in ner_raw]\n",
        "    return pos_tags, ner_entities\n",
        "\n",
        "# Fungsi ekstraksi POS & NER Bahasa Inggris\n",
        "def pos_ner_english(text):\n",
        "    doc = nlp_en(text)\n",
        "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
        "    ner_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return pos_tags, ner_entities\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRFlC7qTEDAg",
        "outputId": "79434bf7-7900-4b5d-b7a3-3461d610c0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cahya/bert-base-indonesian-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for i in range(len(texts[\"id\"])):\n",
        "    text_id = texts[\"id\"][i]\n",
        "    text_en = texts[\"en\"][i]\n",
        "\n",
        "    try:\n",
        "        pos_id_tags, ner_id_spans = pos_ner_indonesian(text_id)\n",
        "    except Exception as e:\n",
        "        pos_id_tags, ner_id_spans = [], []\n",
        "        print(f\"⚠ Gagal proses ID kalimat {i+1}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "    pos_en_tags, ner_en_spans = pos_ner_english(text_en)\n",
        "\n",
        "    results.append({\n",
        "        \"Kalimat (ID)\": text_id,\n",
        "        \"POS (ID)\": pos_id_tags,\n",
        "        \"NER (ID)\": ner_id_spans,\n",
        "        \"Kalimat (EN)\": text_en,\n",
        "        \"POS (EN)\": pos_en_tags,\n",
        "        \"NER (EN)\": ner_en_spans\n",
        "    })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7P1Au7qEFdu",
        "outputId": "8a1d8805-7309-465b-daf4-801e8bd7852f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip instal ipdb\n",
        "%debug\n",
        "import pandas as pd\n",
        "import textwrap\n",
        "\n",
        "def wrap_text(text, width=50):\n",
        "    # Pembungkus teks agar setiap baris tidak lebih dari 'width' karakter\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    return \"\\n\".join(textwrap.wrap(text, width=width))\n",
        "\n",
        "# Misalkan df_view adalah DataFrame hasil format POS dan NER seperti sebelumnya\n",
        "\n",
        "wrap_width = 50  # Lebar maksimal per baris, sesuaikan dengan ukuran layar\n",
        "\n",
        "for col in [\"POS (ID)\", \"NER (ID)\", \"POS (EN)\", \"NER (EN)\"]:\n",
        "    df_view[col] = df_view[col].apply(lambda x: wrap_text(x, wrap_width))\n",
        "\n",
        "# Atur agar output pandas tampil lengkap (tidak terpotong)\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "pd.set_option(\"display.width\", None)  # Bisa diganti dengan angka maksimum sesuai layar\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "print(df_view.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QkKQpVqEXZB",
        "outputId": "f2f31c48-61a8-45c0-8e86-eb0d668df196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kalimatERROR: unknown command \"instal\" - maybe you meant \"install\"\n",
            "> \u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m(1219)\u001b[0;36m_input_request\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m   1217 \u001b[0;31m            \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   1218 \u001b[0;31m                \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m-> 1219 \u001b[0;31m                \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   1220 \u001b[0;31m            \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   1221 \u001b[0;31m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "--KeyboardInterrupt--\n",
            "\n",
            "KeyboardInterrupt: Interrupted by user\n",
            "                                         Kalimat (ID)                                                                                                  POS (ID)                                                 NER (ID)                                                   Kalimat (EN)                                                                                                               POS (EN)                                                          NER (EN)\n",
            "   Jokowi mengunjungi Universitas Indonesia di Depok.               Jokowi/PROPN mengunjungi/VERB Universitas/PROPN\\nIndonesia/PROPN di/ADP Depok/PROPN ./PUNCT [jokowi]<PER> [universitas indonesia]<ORG>\\n[depok]<GPE> President Jokowi visited the University of Indonesia in Depok. President/PROPN Jokowi/PROPN visited/VERB the/DET\\nUniversity/PROPN of/ADP Indonesia/PROPN in/ADP\\nDepok/PROPN ./PUNCT [Jokowi]<PERSON> [the University of\\nIndonesia]<ORG> [Depok]<GPE>\n",
            "        Budi sedang belajar NLP bersama Ani di rumah.             Budi/PROPN sedang/AUX belajar/VERB NLP/PROPN\\nbersama/ADP Ani/PROPN di/ADP rumah/NOUN ./PUNCT                       [budi]<PER> [##lp]<EVT> [ani]<PER>                         Budi is studying NLP with Ani at home.                                 Budi/PROPN is/AUX studying/VERB NLP/PROPN with/ADP\\nAni/PROPN at/ADP home/NOUN ./PUNCT                                          [NLP]<ORG> [Ani]<PERSON>\n",
            "Apple diluncurkan oleh Steve Jobs di Amerika Serikat. Apple/PROPN diluncurkan/VERB oleh/ADP Steve/PROPN\\nJobs/PROPN di/ADP Amerika/PROPN Serikat/PROPN\\n./PUNCT   [apple]<ORG> [steve jobs]<ORG> [amerika\\nserikat]<GPE>         Apple was launched by Steve Jobs in the United States.     Apple/PROPN was/AUX launched/VERB by/ADP\\nSteve/PROPN Jobs/PROPN in/ADP the/DET United/PROPN\\nStates/PROPN ./PUNCT       [Apple]<ORG> [Steve Jobs]<PERSON> [the United\\nStates]<GPE>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lOKT2e_lEZ1v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}